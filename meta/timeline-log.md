# âŒ›ðŸ§‘â€ðŸ’» Project Timeline & My activity Log

- **Oct 22, 2025** â€“ Dataset downloaded & collected.
- **Oct 23, 2025** - Added Data Dictionary of HCES 2023-24 with Links.
- **Oct 24, 2025** 
  - Break the big data into smaller Parquet dataset
  - With Log file and modular code
  - Error in 2, 12, 13, 14 file
  - Level 2 is incorrect file name 
  - Level 12, 13, 14 corrupt file --> again downloaded 
  - Final Review at 20:38 IST
- **Oct 25, 2025**
  - Chunks are too small less 1MB 
  - So converted into a single parquet data for each level 11:42 IST
  - During the csv file conversion level 2 file is corrupt 18:15 IST
    - So again Download dta file then chunk wise 
    - Then convert to merged parquet file 
    - Then csv file. 
    - Rather than Running the whole scripts i do with notebook. 18:58 IST
  - Create the data profiling on each level.
    - If dataset is more than 500 MB 
    - Then it take only 2_000_000 rows 19:42 IST
  - Generate the auto viz to Visualize the data
    - Take the sample of 1_00_000 rows 
    - I think it take time ðŸ˜… Now is 21:30 IST
    - Check the log for more details Now done 23:26 IST
    - Few error is occur but we do in raw datasets 
    - After all the feature engineering done if need we do again 23:38 IST
- **Oct 26, 2025**
  - 07:41 IST >> Add the SSH Key & Push files safely
    - Files are large so issues to commit 
    - Means level scatter plots are doing issues
    - Lev-2 (196MB), Lev-3 (110MB), Lev-09 (415MB), Lev-15  (114MB) ...etc
    - So do some gpt work then finally done 08:38 IST
    - Finally, All published & git is clean from both local and remote 08:57 IST
  - 11:42 IST >> Organize the files for better access
    - Organize file is most important for the project and team work 12:03 IST